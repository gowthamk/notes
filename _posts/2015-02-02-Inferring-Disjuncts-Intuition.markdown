---
layout: post
title:  "Unification-based Type Inference Algorithm for Catalyst"
--- 

This wiki:

1. Describes the intuition behind the unification-based inference
   algorithm,
2. Formalizes the algorithm in two steps: first for simple
   non-recursive functions, and then for recursive functions, and
3. Formalizes expected metatheoretic properties of the inference
   algorithm (proof pending).

Preliminaries
-------------

Since a dependent type inference algorithm has to effectively
synthesize logical formulas, it is imperative that we first fix the
grammar of these formulas. To start with, we fix it to the following
simple syntax:

$$
  \begin{array}{lcl}
  R & \in & Structural\; Relations\\
  v & \in & Variables\; in\; scope\\
  Ratom & ::= & R(v) \;|\; R(v) \times Ratom\\
  Rexpr & ::= & Ratom \;|\; Ratom \cup Rexpr \\
  \phi & ::= & Rapp = Rexpr \;|\; \phi \wedge \phi\\
  \end{array}
$$

Our type inference algorithm relies on certain characteristics of the
grammar defined above. Firstly, a type refinement is simply a
conjunction of equality predicates on relational expressions.
Secondly, equality predicates are of the form $$Rapp = Rexpr$$, where
$$Rapp$$ is presumed to be a relational abstraction of the result
(e.g: `Rmem(v)`), and $$Rexpr$$ is the relational expression, which is
a union of cross-products of relational abstractions of program
variables (presumably inputs). Put together, this means that the job
of type inference algorithm is to simply define relational
abstractions of function result as a either a union of relational
abstractions of function inputs, or a union of their cross-product
combinations. If we refer to a term in the union as a disjunct, the
purpose of type inference algorithm is to infer all disjuncts, whose
union is equivalent to a relational abstraction of the result.

For a moment, ignore type inference and consider only type checking.
In order to determine whether a function `f` has a given relational
type `T`, Catalyst's dependent type checking algorithm analyzes `f`
and generates Verification Conditions (VCs) whose validity determines
the validity of `f:T`. These VCs are of the form $$\Sigma\vdash
\phi$$, where $$\Sigma$$ is a conjunction of propositions capturing
path constraints, and $$\phi$$ is the result type refinement. Note
that path constraints also result from type refinements of either
constructors or other functions. For example, if a certain list `l` is
`y::ys` along this path and `cons` has the type `cons : x -> xs -> {v
| Rmem(v) = {x} U Rmem(xs)}`, then the proposition `Rmem(l) = {x} U
Rmem(xs)` will be a conjunct in $$\Sigma$$. Likewise, if a list `xys`
resulted from concatenation of two lists `xs` and `ys`, and `concat`
has the type `concat: l1 -> l2 -> {l | Rmem(l) = Rmem(l1) U
Rmem(l2)}`, then the proposition `Rmem(xys) = Rmem(xs) U Rmem(ys)`
will be recorded in $$\Sigma$$. Therefore, conjuncts in $$\Sigma$$
adhere to the grammar of type refinements shown above. 

In practice, the grammar of conjuncts in $$\Sigma$$ differs slightly
from the one shown above; When a variable `y` is let-bound to variable
`x:Tx`, instead of recording `R(y) = R(x)` for every relation `R` on
type `Tx`, Catalyst simply records `y = x` in $$\Sigma$$.
Consequently, we also have variable equalities, along with equalities
of form `Rapp = Rexpr` in $$\Sigma$$. This is demonstrated by
following VC generated by Catalyst along `x_0=x::xs` branch of `concat`
function (here, `concat : x_0 -> x_1 -> {v_11 | Rmem(v_11) = Rmem(x_0)
U Rmem(x_1)}`):

    bindings(
       v_11 :  'a_4258 list,
       x_1 :  'a_4258 list,
       x_0 :  'a_4258 list,
       anc_18 :  'a_4258 list,
       anc_19 :  'a_4258 list,
       l1 :  'a_4258 list,
       l2 :  'a_4258 list,
       x : 'a_4258,
       xs :  'a_4258 list,
       anc_21 : 'a_4258,
       anc_24 :  'a_4258 list)
    in
          anc_19 = x_1
          anc_18 = x_0
          l2 = x_1
          l2 = anc_19
          l1 = x_0
          l1 = anc_18
          Rmem(l1) = ({(x)} U Rmem(xs))
          Rhd(l1) = {(x)}
          Rmem(anc_24) = Rmem(xs) U Rmem(l2)
          anc_21 = x
          Rmem(v_11) = ({(anc_21)} U Rmem(anc_24))
          Rhd(v_11) = {(anc_21)}
       =>
          Rmem(v_11) = Rmem(x_0) U Rmem(x_1)
    end

The above format of VC also records ML type bindings of variables, and
represents $$\Sigma \vdash \phi$$ as $$\Sigma => \phi$$. Observe that
$$\Sigma$$ contains variable equalities like `l1=x_0`. These
equalities of form `x=y` can be easily eliminated from the VC, either
by replacing them with `R(x)=R(y)` for every possible relation `R`, or
by simply substituting `y` for `x` wherever applicable. The VC after
such elimination is shown below (ML type bindings elided):

    bindings ... 
    in
          Rmem(x_0) = ({(x)} U Rmem(xs))
          Rhd(x_0) = {(x)}
          Rmem(anc_24) = Rmem(xs) U Rmem(x_1)
          Rmem(v_11) = ({(x)} U Rmem(anc_24))
          Rhd(v_11) = {(x)}
       =>
          Rmem(v_11) = Rmem(x_0) U Rmem(x_1)
    end

Observe that in the above VC, if we replace every term of form`R(x)`
or `{(x)}` with a unique uninterpreted set variable, the resultant
sequent is still equivalent to the above VC. We make this
transformation adopting the following convention on set variables:
relational abstractions of inputs (`Rmem(x_0)` and `Rhd(x_0)` in this
case) are represented by set variables starting with capital letter
$$S$$. Sets and relational abstractions of intermediary variables (eg:
`x`, `xs`) are represented by set variables starting with small letter
$$s$$. Finally, for sets and abstractions of result variable (`v_11`)
here, we use symbols starting with `σ`. The transformed VC is the
sequent below:

      S0 = s1 U s0
      S1 = s1
      s2 = s0 U S2
      σ0 = s1 U s2
      σ1 = s1
    ----------------
      σ0 = S0 U S2
    ----------------

Any SMT solver with theory of sets can discharge the above sequent
very easily. Although this method is not how Catalyst encodes VCs, it
is one of the encoding techniques that were considered.

Now, consider the type inference problem, where the type of `concat`
is not known, but needs to be inferred. Let us say someone told us
that the type of `concat` fits in the following template: 

    concat : x_0 -> x_1 -> {v_11 | Rmem(v_11) = ?? }

Where, `??` is a hole that need to be filled with a relational
expression `re` such that it is well-formed under (i.e., its freevars
are subset of) {`x_0`,`x_1`}. In this case, the set-theoretic sequent
reprsenting the VC will be of the following form:

      S0 = s1 U s0
      S1 = s1
      s2 = re'
      σ0 = s1 U s2
      σ1 = s1
    ----------------
      σ0 = re
    ----------------

Relational expression `re'` is the result of the recursive call, and
stands for `[xs/x_0]re`. It is now the job of the inference algorithm
to infer all the disjuncts in `re` such that the sequent is valid.
This problem is tough as `concat` is a recursive function, and the
sequent contains mutually dependent holes in antecedent and
consequent. Therefore, we attempt the easier problem of inferring
types for non-recursive functions first (Note: The current version of
Catalyst does not need type annotations for non-recursive functions,
but it cannot infer their types either; it just simply records the
antecedents of their VCs in type refinements). 

Non-Recursive Functions
-----------------------

Consider the non-recursive function `foo` that reverses the order of
first two elements of its input list:

    fun foo l = case l of 
      [] => l
    | x::xs => case xs of 
        [] => l
      | x'::xs' => 
        let
          val v' = x::xs'
          val v = x'::v'
        in
          v
        end

Let us start with the following template for `foo`:

    foo : l -> {v | Rmem(v) = ??}

Its VC (along `l = x::x'::xs'` path) is shown below:

    bindigs ...
    in
        Rmem(l) = {(x)} U Rmem(xs)
        Rhd(l) = {(x)}  
        Rmem(xs) = {(x')} U Rmem(xs')
        Rhd(xs) = {(x')}
        Rmem(v') = {(x)} U Rmem(xs')
        Rhd(v') = {(x)}
        Rmem(v) = {(x')} U Rmem(v')
        Rhd(v) = {(x')}
      =>
        Rmem(v) = ??
    end

There are no variable equalities in VC to eliminate. After encoding in
terms of uninterpreted set variables, the sequent is:

      S0 = s2 U s3
      S1 = s2  
      s3 = s4 U s5
      s6 = s4
      s7 = s2 U s5
      s8 = s2
      σ9 = s4 U s7
      σ10 = s4
    -------------------
      σ9 = ??
    -------------------

The aim of type inference now is to define `σ10` in terms of `S0` and
`S1`. This is now a constraint satisfaction problem with equational
constraints on sets. The solution to this system of constraints is a
substitution function `γ : σ -> RE(S)`, where `RE(S)` denotes the set
of all relational expressions on the set of `S`s in the constraint
system. For the constraint system with equational constraints as shown
above, `RE(S) = RE({S0,S1})` is the set of all relational expressions
on `S0` and `S1`.

For the sake of simplicity, we want our equational constraints to
satisfy certain properties. Towards this end, we make some assumptions
about the kind of functions that our inference algorithm considers:

1. Functions are non-recursive.
2. There are no pre-conditions. That is, function inputs have trivial
   type refinements.
3. We assume that the return value of a function/constructor
   application is never pattern-matched.
4. Any variable (including function arguments) is bound only once.
   Further, we assume that there are no duplicate pattern matches; for
   e.g., a list `l` is never destructed twice along the same path. 

Going forward, we will relax conditions 1, 2 and 3. Due to the
simplicity of our grammar, and above assumptions about functions being
analyzed, equational constraints in set-encoding of generated VCs
satisfy certain pleasant properties:

1. LHS of all equations is a single set variable. This follows from
   `Rapp = Rexpr` grammar of refinements. This restriction will remain
   even as we complicate the grammar.
2. If the LHS of an equation is big `S` (we call such equation as an
   _input equation_), then its RHS does not contain a big `S`. This is
   because:
   1. There are no preconditions. Hence, there are no equations
      relating relational abstractions of inputs.
   2. Input vars are never rebound; hence, cannot denote return value
      of function calls or alias another input variable.
3. Like input equations, let us define _output equations_ as those
   whose LHS is a `σ`. Equations other than input and output equations
   are those whose LHS is an `s`. They are called _intermediary
   equations_. If two equations have same LHS, they are called
   _duplicate equations_. Can there can be duplicate equations among
   equational constraints generated during type inference? A trivial
   reason for the presence of duplicate equations is duplicate pattern
   matches. For instance, if a list `l` is matched agains `x::xs`, and
   is again matched against `y::ys` in the match expression, the VC
   generated will contain duplicate equations for `Rmem(l)`. This can
   be true of input, intermediary, as well as output equations.
   Another trivial source of duplicate equations is the presence of
   duplicate _let_ bindings. The more practical source of duplicate
   equations is pattern matching on return values of function calls.
   For example, if a list `l` denotes the return list of a call to
   concat function, and it `l` is subsequently matched against
   `x::xs`, the VC generated contains two equations for `Rmem(l)`: one
   from the type of concat, and another from the pattern match.
   Pattern matching function return values can be the source of
   duplication for intermediary and output equations. Fortunately,
   assumptions 3 and 4 we made above preclude possibility of any
   duplicate equations.
4. Let us define an inductive property `P_imem` over `S U s U σ` as
   following:
   1. Forall `Si ∈ S`, `P_imem(Si)` is true
   2. In an equation `ψ = re`, where `ψ ∈ S U s U σ`, if `P_imem(ψ)`
      is true, then forall `ψ' ∈ free-set-vars(re)`, `P_imem(ψ')` is
      true.
   3. In an equation `ψ = re`, where `ψ ∈ S U s U σ`, if forall `ψ' ∈
      free-set-vars(re)`, `P_imem(ψ')` is true, then `P_imem(ψ)`
      is true.
   4. `P_imem` is false elsewhere.

   Observe that for any set `ψ ∈ s U σ`, `P_imem(ψ)` is true if
   and only if its elements can be traced back to an input relational
   abstraction. We now prove a useful lemma: 

       Lemma 1: a solution (γ) to a system of equational constraints
       exists only if forall σi ∈ σ, P_imem(σi) is true.
       Proof. If P_imem(σi) is false, then there exist elements of
       σi that cannot be traced back to input relational
       abstractions.  Therefore, it is impossible to express σi as a
       union/cross-product combination of input relational
       abstractions, which means that the function γ is undefined.

   Alternatively, if we allow `γ` to be a partial function, then
   `γ(σi)`, for some `σi` is defined only if  `P_mem(σi)` is true.
   Note that for any non-trivial recursive function, there exist
   output relational abstractions (`σ`s) which violate the `P_mem`
   property.  This is because the output equations for such `σ`s refer
   to relational abstractions of the result of the recursive call,
   which cannot be traced back to input equations, unless we already
   know the invariant that recursive call satisfies (i.e., the type of
   the function being analyzed). For example, equation for
   `Rmem(v_11)` in the VC for concat refers to `Rmem(anc_24)`, where
   `anc_24` is the variable storing the result of the recursive call,
   and elements of `Rmem(anc_24)` clearly cannot be traced back to
   input relational abstractions of concat, unless the type of concat
   is known beforehand. This makes it clear that a solution in form of
   the substitution function `γ` does not exist for constraints
   generated from recursive functions. We have to generalize the
   notion of solution as we solve such constraints. This we will do
   once we start considering recursive functions.

The above observations lead us towards an algorithm to solve
equational constraints. It is shown below (the main function is a
function named `solve` defined at the end).

{% highlight ocaml %}
    fun simplifyConstraints (c::cs) acc = case c of
          `S = ...` => simplifyConstraints cs (c::acc)
        | `ψ = re` (* ψ is either s or σ *)=> 
            let
              val substf = [ψ ↦ re]
              val cs' = map (toDNF $ applySubst substf) cs
              val acc' = map (toDNF $ applySubst substf) acc
            in
              simplifyConstraints cs' acc'
            end
      | simplifyConstraints [] acc = acc

    fun unifiable (ratom1,ratom2) = case (ratom1,ratom2) of 
        (rapp1,rapp2) => rapp1 = rapp2
      | (rapp1 `X` ratom1', rapp2 `X` ratom2') => 
          (rapp1 = rapp2 andalso unifiable (ratom1',ratom2'))
      | _ => False
    (*
     * re1 and re2 should both be in DNF.
     * Verifies if disjuncts of re1 are present in re2. If yes, 
     * returns left-over disjuncts in re2. Otherwise, raises
     * CantUnify.
     *)
    fun tryUnify (re1,re2)  = case re1 of 
        ratom => 
          let
            val isUnifiable = ref False
            val leftOvers = List.keepAll
              (fn (disj) => if unifiable (ratom,disj) 
                then (isUnifiable := True; False)
                else True) (allDisjunctsIn re2)
            val _ = if (not (!isUnifiable)) 
              then raise CantUnify else ()
          in
            mkUnion leftOvers
          end
      | ratom `U` re1' => 
          let
            val re2' = tryUnify (ratom,re2)
          in
            tryUnify (re1',re2')
          end
    (*
     * Returns a list of (S,ob) pairs, where the RHS of input equation
     * of S contains ratom as one of its disjuncts, and ob is the
     * union of remaining disjuncts.
     * Raises CantUnify if no such S exists.
     *)
    fun tryUnifySome (ratom, inputEqs) = 
      case (List.keepAllMap  
          (fn (S `=` sre) => 
            let
              val sreLeft = tryUnify (ratom,sre)
            in
              SOME (S,sreLeft)
            end handle CantUnify => NONE) inputEqs) of
        [] => raise CantUnify
      | l => l

    (*
     * Given a list of RApps in a cross-product, generates a list
     * of all possible splits of the list whose cross product yeilds
     * the original cross product. Each element in the returned list
     * is a split. Each split is represented as a list of conjuncts.
     * Each conjunct is represented as a list of set variables.
     *)
    fun allCPSplits (rapps : rapp list) : ratom list list  = 
      let
        fun mkCPCombos l1 l2 = case (l1,l2) of 
            (l1,[]) => []
          | (l1,rapp::l2') => 
              let
                val resl1l2split = List.crossPrd concat 
                  (allCPSplits l1) (allCPSplits l2)
                val res' = mkCPCombos (snoc (l1,rapp)) l2'
                val fullRes = concat resl1l2split res'
              in
                fullRes
              end
        val splits = case rapps of 
            [] => []
            [rapp] => [[[rapp]]]
          | fstRApp::rstRApps => [[rapps]]::  
                  (mkCPCombos [fstRApp] rstRApps)
        val ratomss = List.map (fn split => List.map 
          (fn svars => crossPrdOf conj) svars) splits
      in
        ratomss
      end

    fun hypothesizeCombos inputEqs ratom = 
      let
        val (splits: ratom list list) = allCPSplits ratomToList $ ratom
        val sol_obs = List.map (fn ratoms => 
          let
            val sol_obs = List.concat $ List.keepAllMap 
              (fn ratom => tryUnifySome (ratom,inputEqs)) ratoms
            val (sols,obs) = List.unzip sol_obs
            val sol = crossPrdOf sols
            val ob = toDNF $ crossPrdOf obs
          in
            SOME (sol,ob)
          end handle CantUnify => NONE) splits
      in
        sol_obs
      end
    
    fun findAllInputCombos inputEqs re = case re of 
        (* assume there are no constant sets except ∅ *)
        `∅` => 
          let
            val sol_obs =  hypothesizeCombos inputEqs `∅`
            val sols = keepAllMap (fn (sol, `∅`) => SOME sol 
                (* No further obligations are admitted *)
              | _ => NONE)
          in
            `∅`::sols
          end
      | ratom => findAllInputCombos inputEqs (ratom `U` ∅)
      | ratom `U` re' => 
          let
            val sol_obs =  hypothesizeCombos inputEqs ratom
            val sol_resREs = List.keepAllMap 
              (fn (sol,ob) => 
                let
                  val residueRE = tryUnify (ob,re')
                in
                  SOME (sol,residueRE)
                  (*
                   * This algorithm does not guarantee completeness.
                   * It will not succeed if the solution is supposed
                   * to contain two disjuncts with overlapping tuples. 
                   * Conjecture: We can guarantee completeness if we
                   * return SOME [(sol,residueRE), (sol,re')]
                   *)
                end handle CantUnify => NONE) sol_obs
            val combos = List.concat $ List.map 
              (fn (sol,resRE) => 
                let
                  val resREsols = findAllInputCombos inputEqs resRE
                  (*
                   * Observe that if resREsols is an empty list, we
                   * return an empty list.
                   *)
                  val sols = List.map (fn resREsol => sol `U` resREsol)
                    resREsols
                in
                  sols
                end) sol_resREs
          in
            combos
          end

    fun solve (cs, σi) =
      let
        val (restCs, [σiEqn]) = List.partition 
          (fn (`σj = ...`) if σj = σi then RIGHT else LEFT 
            | _ => LEFT) cs
        val cs' = simplifyConstraints restCs [σiEqn]
        val (inputEqs,[σiEqn']) = List.partition
          (fn (`σj = ...`) if σj = σi then RIGHT else 
              error "No output eqn except σi's should remain after \
                \ constraint simplification"
            | `S = ...` => LEFT
            | `s = ...` => fail () (* This case never reached *)) cs
        val σiEqnRhs = case σiEqn' of `.. = re` => 
          (assert (∀k. σk ∉ freeVars(re), "No Solution"); re)
        val σiEqnRhsList = findAllInputCombos inputEqs σiEqnRhs
      in
        σiEqnRhsList 
      end
{% endhighlight %}

<!--

    case ratom of 
        rapp => List.keepAllMap  (* ∅ is counted here as ∅ is Rnull application *)
          (fn (S `=` sre) => 
            let
              val sreLeft = tryUnify (rapp,sre)
            in
              SOME (S,sreLeft)
            end handle CantUnify => NONE) inputEqs
      | rapp `X` ratom' => 
          let
            val rappSolObs = hypothesizeCombos inputEqs rapp
            val ratomSolObs = hypothesizeCombos inputEqs ratom
            val solObs = List.crossPrd 
              (fn ((sol1,ob1),(sol2,ob2)) => 
                  (sol1 `X` sol2, toDNF $ ob1 `X` ob2)) 
              rappSolObs ratomSolObs
          in
            solObs
          end

-->

The algorithm takes a list (`cs`) of equational constraints on set
variables and an output set variable (`σi`), solves the constraints,
and generates a solution for `σi` that defines it as a union/crossprd
combination of of input set variables (`S`). It first simplifies
constraints by removing all intermediary equations (those with an `s`
as their LHS). Next, it tries to unify disjuncts in the RHS of the
output equation of `σi` (`σiEqnRhs`) with disjuncts in RHS of input
equations. In the process, it generates hypotheses about disjuncts in
the solution. Each hypothesis is then verified. While valid hypotheses
are retained, invalid ones are discarded. This process is repeated
until we exhaust all disjuncts in `σiEqnRhs`, or until we encounter a
disjunct in `σiEqnRhs` that could not be unified.

Now, let us reconsider the equational constraint system that we
generated from the verification condition of `foo` function shown
previously:

      S0 = s2 U s3
      S1 = s2  
      s3 = s4 U s5
      s6 = s4
      s7 = s2 U s5
      s8 = s2
      σ9 = s4 U s7
      σ10 = s4
    -------------------
      σ9 = ??
    -------------------

Let us run through the steps of our algorithm. After
`simplifyConstraints`, we have:

      S0 = s2 U s4 U s5
      S1 = s2  
      σ9 = s4 U s2 U s5
    -------------------
      σ9 = ??
    -------------------

We call `findAllInputCombos` with `[S0 = s2 U s4 U s5, S1 = s2]` as
input equations, and `s4 U s2 U s5` as the term to be solved, such
that the solution should express it as a union/crossproduct
combination of `S0` and `S1`.  `findAllInputCombos` calls
`hypothesizeCombos` with same input equations, and `s4` as ratom.
`hypothesizeCombos` generates S0 as the only hypothesis combination,
with `s5 U s2` as the obligation. Now, `tryUnify` unifies `s5 U s2`
with `s2 U s5` leaving no residue. This concludes constraint solving
with a solution of `σ9 = S0` as the only solution.

Recursive Functions
-------------------

The constraints from the VCs of recursive functions cannot be solved
by the algorithm described above. As described previously, the `P_imem`
property can be invalid for output equations for recursive function
VCs. This is because the output equation (after constraint simplification)
might contain a `s` variable (denoting a relational abstraction of the
result of the recursive call) which cannot be be unified with any of
the disjuncts in input equations. Fortunately, this `s` variable
satisfies certain properties:

1. For every hypothesis about a disjunct in the solution, there exists
   a corresponding hypothesis about a disjunct in the expression
   denoted by the `s` variable. For example, consider the concat
   function (`concat : l1 -> l2 -> l`). Assume that we are analyzing
   its recursive branch, where `l1=x::xs`. If we hypothesize that
   `Rmem(l1)` is a disjunct in the equation for `Rmem(l)`, then this
   inevitably means that `Rmem(xs)` is a disjunct in the equation for
   `s`, where `s` stands for `Rmem` abstraction of the result list of
   the recursive call (i.e., `s = Rmem(concat xs l2)`). Consequently,
   when we are validating this hypothesis, `s` can be rewritten as
   `Rmem(xs) U s'`, where `s'` is a fresh set variable.
2. Once only a `s` remains for unification, then it can be unified
   with any union/cross-product combination of input relational
   abstractions (the `S`s) provided that the following conditions are
   met:
   1. The combination is type-safe w.r.t the type (sort) of `s`.
   2. The combination is well-formed w.r.t the conditions under which
      `s`, and *also* the solution, is required to be well-formed.
   3. The resultant solution of `σi` does not contain duplicate
      disjuncts (This is only a "good-to-have" property; No harm is
      done if it is violated.).
   For example, while trying to solve the constraints for concat, we
   start with `Rmem(l) = {x} U s`, where `s` is the `Rmem` abstraction
   of the list from recursive call (`concat xs l2`). Unification of
   `{x}` with RHS of `Rmem(l1)` succeeds (due to property 1 stated
   above), and the output equation becomes `Rmem(l) = Rmem(l1) U s'`.
   Only `s'` remains to be unified. Since `Rmem(l) = Rmem(l1) U s'` is
   the result type refinement, `s'` needs to be well-formed under
   `{l1,l2}`. Further, `s'` is also the invariant of the recursive
   call, so `s'` must be well-formed under `{xs,l2}`. Therefore, `s'`
   can only be unified with (combinations of) relational abstractions
   of `l2`. Therefore `s'` can be one of `{Rmem(l2), Rhd(l2), Rhd(l2)
   U Rmem(l2)}`.

Based on the above observations, we now modify the algorithm that we
presented previously. We start by introducing a new kind of equation
called the _hole equation_. A hole equation is of form `s =
pending-substitutions * α`, where unification variable α stands for
the hole representing the unknown relational expression in the
invariant (type refinement) we are seeking. Pending substitutions are
substitutions resulting from the dependent type rule for function
applications:

$$
  \frac
  {
    f: (x:\tau_1) \rightarrow \tau_2 \quad
    y: \tau_1
  }
  {
    f \, y : [y/x]\,\tau_2
  }
$$

Since we don't yet know the result type (refinement) of the function
(i.e., $$\tau_2$$ _), the substitutions become _pending_.

As usual, the algorithm starts with constraint simplification phase,
which is same as the simplification phase of constraints without hole
equations. At the end of constraint simplification phase, we are left
with input equations and an output equation for the `σi`, where `σi`
denotes a relational abstraction of the output whose invariant we are
trying to infer (e.g: in case of `concat: l1 -> l2 -> l`, `σi` can be
`Rmem(l)` or `Robs(l)`). However, unlike the non-recursive case, the
output equation now contains a disjunct with one of its conjuncts as
`pending-substitutions * α`. We push this disjunct to last, so that
we can defer its unification until the end. We now start unification
with `hypothesizeCombos`.

Generating hypothesis inside `hypothesizeCombos` proceeds as before,
but validating hypothesis is where we make use of our 1st observation.
Here, unlike the non-recursive case, we _apply_ the hypothesis to
derive an invariant from the recursive call before we validate it.
This happens inside the `applyHypothesis` function, where, given a
hypothesis `hyp` denoting a candidate disjunct, we rewrite the hole
`pending-substitutions * α` as `(pending-substitutions o hyp) U 
(pending-substitutions * α)`. The obligations resulting from the
hypothesis are then unified against `(pending-substitutions o hyp)`
along with other disjuncts in `σiEqnRhs`.

Once we succesfully unify all disjuncts in `σiEqnRhs`, we will be left
with only the `α`. Here, we make use of the second observation noted
above: we generate the combinations of all input relational
abstractions (the `S`'s) that have same sort as `α`, and check if
they meet the well-formedness conditions. We retain only those combos
which meet well-formedness conditions. We extend the definition of
`hypothesizeCombos` with a case for `α` to do this.

The algorithm is described below (the main function is a function
named `solve`):

{% highlight ocaml %}
   fun simplifyConstraints (c::cs) acc = case c of
          `S = ...` => simplifyConstraints cs (c::acc)
        | `ψ = re` (* ψ is either s or σ *)=> 
            let
              val substf = [ψ ↦ re]
              val cs' = map (toDNF $ applySubst substf) cs
              val acc' = map (toDNF $ applySubst substf) acc
            in
              simplifyConstraints cs' acc'
            end
      | simplifyConstraints [] acc = acc

    fun unifiable (ratom1,ratom2) = case (ratom1,ratom2) of 
        (rapp1,rapp2) => rapp1 = rapp2
      | (rapp1 `X` ratom1', rapp2 `X` ratom2') => 
          (rapp1 = rapp2 andalso unifiable (ratom1',ratom2'))
      | _ => False
    (*
     * re1 and re2 should both be in DNF.
     * Verifies if disjuncts of re1 are present in re2. If yes, 
     * returns left-over disjuncts in re2. Otherwise, raises
     * CantUnify.
     *)
    fun tryUnify (re1,re2)  = case re1 of 
        ratom => 
          let
            val isUnifiable = ref False
            val leftOvers = List.keepAll
              (fn (disj) => if unifiable (ratom,disj) 
                then (isUnifiable := True; False)
                else True) (allDisjunctsIn re2)
            val _ = if (not (!isUnifiable)) 
              then raise CantUnify else ()
          in
            mkUnion leftOvers
          end
      | ratom `U` re1' => 
          let
            val re2' = tryUnify (ratom,re2)
          in
            tryUnify (re1',re2')
          end
    (*
     * Returns a list of (S,ob) pairs, where the RHS of input equation
     * of S contains ratom as one of its disjuncts, and ob is the
     * union of remaining disjuncts.
     * Raises CantUnify if no such S exists.
     *)
    fun tryUnifySome (ratom, inputEqs) = 
      case (List.keepAllMap  
          (fn (S `=` sre) => 
            let
              val sreLeft = tryUnify (ratom,sre)
            in
              SOME (S,sreLeft)
            end handle CantUnify => NONE) inputEqs) of
        [] => raise CantUnify
      | l => l

    (*
     * Given a list of RApps in a cross-product, generates a list
     * of all possible splits of the list whose cross product yeilds
     * the original cross product. Each element in the returned list
     * is a split. Each split is represented as a list of conjuncts.
     * Each conjunct is represented as a list of set variables.
     *)
    fun allCPSplits (rapps : rapp list) : ratom list list  = 
      let
        fun mkCPCombos l1 l2 = case (l1,l2) of 
            (l1,[]) => []
          | (l1,rapp::l2') => 
              let
                val resl1l2split = List.crossPrd concat 
                  (allCPSplits l1) (allCPSplits l2)
                val res' = mkCPCombos (snoc (l1,rapp)) l2'
                val fullRes = concat resl1l2split res'
              in
                fullRes
              end
        val splits = case rapps of 
            [] => []
            [rapp] => [[[rapp]]]
          | fstRApp::rstRApps => [[rapps]]::  
                  (mkCPCombos [fstRApp] rstRApps)
        val ratomss = List.map (fn split => List.map 
          (fn svars => crossPrdOf conj) svars) splits
      in
        ratomss
      end

    fun hypothesizeCombos dom inputEqs ratom = case ratom of 
        Alpha (sort,substf) => 
          let
            (*
             * Generate all input combinations of the sort that 
             * α is supposed to be.
             *)
            val inpCombos = allCombos dom sort
            (*
             * Retain only ones that are idempotent under
             * substitution. Only they meet the well-formedness
             * condition described in point 2 previously (Above this
             * algorithm)
             *)
            val validCombos = List.keepAll (fn comboRE => 
              applySubst substf comboRE = comboRE 
                handle NoSubst => False) inpCombos
          in
            validCombos
          end
      | _ => 
          let
            val (splits: ratom list list) = allCPSplits ratomToList $ ratom
            val sol_obs = List.map (fn ratoms => 
              let
                val sol_obs = List.concat $ List.keepAllMap 
                  (fn ratom => tryUnifySome (ratom,inputEqs)) ratoms
                val (sols,obs) = List.unzip sol_obs
                val sol = crossPrdOf sols
                val ob = toDNF $ crossPrdOf obs
              in
                SOME (sol,ob)
              end handle CantUnify => NONE) splits
          in
            sol_obs
          end
          

    fun applyHypothesis hyp re = 
      let
        fun doItRatom ratom = case ratom of
            Alpha (sort, substf) => (applySubst substf hyp) `U` 
              ratom) handle NoSubst => ratom
          | rapp => rapp
          | s `X` ratom => toDNF $ (doItRatom s) `X` (doItRatom ratom)
      in
        case re of
          ∅ => ∅
        | ratom => doItRatom ratom
        | ratom `U` re' => (* α is always in the last disjunct *)
              ratom `U` (applyHypothesis hyp re')
      end  

    fun findAllInputCombos dom inputEqs re = case re of 
        (* assume there are no constant sets except ∅ *)
        `∅` => 
          let
            val sol_obs =  hypothesizeCombos dom inputEqs `∅`
            val sols = keepAllMap (fn (sol, `∅`) => SOME sol 
                (* No further obligations are admitted *)
              | _ => NONE)
          in
            `∅`::sols
          end
      | ratom => findAllInputCombos dom inputEqs (ratom `U` ∅)
      | ratom `U` re' => 
          let
            val hyp_obs =  hypothesizeCombos dom inputEqs ratom
            val hyp_resREs = List.keepAllMap 
              (fn (hyp,ob) => 
                let
                  val re'' = applyHypothesis hyp re'
                  val residueRE = tryUnify (ob,re'')
                in
                  SOME (hyp,residueRE)
                  (*
                   * This algorithm does not guarantee completeness.
                   * It will not succeed if the solution is supposed
                   * to contain two disjuncts with overlapping tuples. 
                   * Conjecture: We can guarantee completeness if we
                   * return SOME [(sol,residueRE), (sol,re'')]
                   *)
                end handle CantUnify => NONE) hyp_obs
            val combos = List.concat $ List.map 
              (fn (sol,resRE) => 
                let
                  val resREsols = findAllInputCombos dom inputEqs resRE
                  (*
                   * Observe that if resREsols is an empty list, we
                   * return an empty list.
                   *)
                  val sols = List.map (fn resREsol => sol `U` resREsol)
                    resREsols
                in
                  sols
                end) sol_resREs
          in
            combos
          end

    fun solve (dom, cs, σi) =
      let
        val (restCs, [σiEqn]) = List.partition 
          (fn (`σj = ...`) if σj = σi then RIGHT else LEFT 
            | _ => LEFT) cs
        val cs' = simplifyConstraints restCs [σiEqn]
        val (inputEqs,[σiEqn']) = List.partition
          (fn (`σj = ...`) if σj = σi then RIGHT else 
              error "No output eqn except σi's should remain after \
                \ constraint simplification"
            | `S = ...` => LEFT
            | `s = ...` => fail () (* This case never reached *)) cs
        val σiEqnRhs = case σiEqn' of `.. = re` => 
          (assert (∀k. σk ∉ freeVars(re), "No Solution"); 
            (* push α to the last conjunct of the last disjunct *)
           pushAlpha re)
        val σiEqnRhsList = findAllInputCombos dom inputEqs σiEqnRhs
      in
        σiEqnRhsList 
      end 
{% endhighlight %}

To see how algorithm works, consider the (simplified) VC of 
with holes (`concat : x_0 -> x_1 -> {v_11 | ??0}`):

    bindings ... 
    in
          Rmem(x_0) = ({(x)} U Rmem(xs))
          Rhd(x_0) = {(x)}
          Rmem(anc_24) = [xs/x_0][x_1/x_1]??0
          Rmem(v_11) = ({(x)} U Rmem(anc_24))
          Rhd(v_11) = {(x)}
       =>
          Rmem(v_11) = ??0
    end

For the sake of simplicity, assume that we only have `Rhd` and `Rmem`
relations.

We first anonymize relation applications with set variables, and then
introducing α to denote the uknown relational expression. This results
in input, hole and output equations as shown below:

      S0 = s1 U s0
      S1 = s1
      s2 = [s0/S0][•/S1][S2/S2][S3/S3] α
      σ0 = s1 U s2
    ----------------
      σ0 = ??
    ----------------

The sets `S0-3` stand for input relational abstractions `Rmem(x_0)`,
`Rhd(x_0)`, `Rmem(x_1)`, and `Rhd(x_0)`, respectively. Note that
program-variable level substitutions `[xs/x_0][x_1/x_1]` have been
lifted to set-variable level substitutions
`[s0/S0][•/S1][S2/S2][S3/S3]` in the encoded VC. To solve the
constraints, we call `solve` with `{S0,S1,S2,S3}` as domain (`dom`) of
the solution,`[S0 = s1 U s0, S1 = s1, s2 = [s0/S0][•/S1][S2/S2][S3/S3]
α]` as constraints (`cs`), and `σ0` as the output relational
abstraction (`σi`) for which the invariant needs to be inferred. 

After `simplifyConstraints` phase:

      S0 = s1 U s0
      S1 = s1
      σ0 = s1 U [s0/S0][•/S1][S2/S2][S3/S3]α
    ----------------
      σ0 = ??
    ----------------

Since `σi` is `σ0`, `σiEqnRhs` is `s1 U [s0/S0][•/S1][S2/S2][S3/S3]α`.
Its first disjunct `s1` can be unified with RHS of either `S1` or
`S0` resulting in hypothesis-obligation pairs of `[(S1,∅),(S0,s0)]`.
If we _apply_ these hypotheses to `α`, the resultant disjuncts are
(respectively): 

+ `[s0/S0][•/S1][S2/S2][S3/S3] S1`, which is equal to `•` - a value
  against which nothing can be unified; not even the empty set.
+ `[s0/S0][•/S1][S2/S2][S3/S3] S0`, which is equal to `s0`.

Finally, we now try to discharge obligations generated along with
both the hypotheses, by unifying them with above disjuncts
(respectively). While unification of `∅` with `•` fails, prompting us to
discard first hypothesis, unification of `s0` with `s0` succeeds
validating the second hypothesis. Hence, we infer that the solution
for `σ0=??` can be of form `σ0 = S0 U ...` and move ahead to fill in
`...`. 

Since `s1` has been unified, the only disjunct left in `σiEqnRhs` is
`[s0/S0][•/S1][S2/S2][S3/S3]α`. Any union combination of of input
relational abstractions match the sort of `α`. Examples of such
combinations include:

    S0, S1, S0 U S1, S2, S3, S2 U S3, S0 U S2 U S3, ..

Of these, only `S2`, `S3`, `S2 U S3` are idempotent w.r.t the
substitution function `[s0/S0][•/S1][S2/S2][S3/S3]` (Why do we
consider idempotence? Only the combinations that are idempotent under
the substitution function meet the well-formedness constraint
described in our observation #2). We use these combinations to fill
the `...` resulting in the following final set of solutions for the
invariant:


      1. σ0 = S0 U S2
      2. σ0 = S0 U S3
      3. σ0 = S0 U S2 U S3

Now, if we de-anonymize sets and convert them back to relation
applications, the above equations stand for the following:

      1. Rmem(l) = Rmem(x_0) U Rmem(x_1)
      2. Rmem(l) = Rmem(x_0) U Rhd(x_1)
      3. Rmem(l) = Rmem(x_0) U Rmem(x_1) U Rhd(x_1)

Note that we have so far only considered the recursive branch
(`x0_x::xs` branch) of concat. If we generate VC and do constraint
solving on non-recursive branch (for this, previous version of our
algorithm suffices), we get the following equations:

      1. Rmem(l) = Rmem(x_1) U Rmem(x_0)
      2. Rmem(l) = Rmem(x_1) U Rhd(x_0)
      3. Rmem(l) = Rmem(x_1) U Rmem(x_0) U Rhd(x_0)

Observe that 1st equations generated from both the branches are
equivalent; the rest don't match. Therefore, the only candidate
invariant we generate is `Rmem(l) = Rmem(x_0) U Rmem(x_1)`.
Fortunately, this invariant passes the verification check; so, it is
infact the final invariant of the concat function.

Soundness of the Algorithm
--------------------------

If we know that our algorithm for solving equational constraints on
sets is sound, we do not need a verification step at the end to check
that generated invariant is indeed a valid invariant. Before we prove
that our algorithm is sound, we have to define what we mean by
soundness. Towards this end, we first list relevant axioms of set
theory:

Set theoretic axioms:

$$
  \frac{
   }
   {
    x \notin \emptyset 
   }
$$

$$
  \frac{
   }
   {
    x \in \{x\}
   }
$$

$$
  \frac{
    \forall x.\, x\in S_1 \Leftrightarrow x \in S_2
   }
   {
    S_1 = S_2
   }
$$

$$
  \frac{
    x\in S_1 
   }
   {
    x \in S_1 \cup  S_2
   }
$$

$$
  \frac{
    x\in S_2
   }
   {
    x \in S_1 \cup  S_2
   }
$$

$$
  \frac {
    x\in S_1 \quad y \in S_2
  }
  {
    (x,y) \in S_1 \times S_2
  }
$$

$$
  \frac{
    x_0 = x_1 \quad y_0 = y_1
  }
  {
    (x_0,y_0) = (x_1,y_1)
  }
$$

First, let us only consider simple VCs (without holes in the
antecedent) generated from non-recursive functions. Let us assume that
set encoding of the VC is correct (this is an orthogonal problem, and
needs to be proven as a seperate lemma). The encoded VC is of form $$
    cs \vdash \sigma_i = ?? $$. The antecedent is a series equational
constraints (`cs`) on set-variables belonging to three classes - the
`S` variables, `s` variables and `σ` variables. The hole in the
consequent denotes an unknown relational expression, which
needs to be discovered through constraint solving. We formally denote
this constraint system as $$
    (S,\;cs \vdash \sigma_i = ??)$$, and define the constraint
satisfaction problem as the following:

$$
    \text{Definition (Constraint Satisfaction Problem): Given a
    constraint system } (S,\; cs \vdash \sigma_i = ??),\\
    \text{find a relational expression } re \text{ such that } 
    freeVars(re) ⊆ S \text{, and } \\
    (\bigwedge cs) \vdash (\sigma_i = re) \\
    \text{ is valid in the axiomatic system defined by set theoretic axioms}
$$

We now claim that first version of our algorithm (call it $$A1$$) is sound: 

$$
    \text{Theorem 1 (Algorithm A1 is sound): every } re \text{
    returned by } \\ {\sf solve(S,cs,\sigma_i)} \text{ is a solution of }
    (S,\; cs \vdash \sigma_i = ??).
$$

Let us now consider VCs with holes in the antecedent generated from
non-recursive functions. Set encoding generates a VC of form: $$
    cs \vdash ({\sigma_i} = \alpha_i) $$. As usual, free set-variables
in equational constraints can be partitioned into three classes - the
`S` variables, `s` variables and `σ` variables. Equational constraints
now also include _hole equations_, whose RHS is a hole represented as
`pending-substitutions * αj`, where `αj` is a unification variable ()
denoting an unknown relational expression (note that, unlike a
set-variable, which denotes a concrete set, a unification variable is
an abstract variable denoting an expression). We now define constraint
satisfaction problem as:

$$
    \text{Definition (Constraint Satisfaction Problem): Given a
    constraint system } (S,\; cs \vdash \sigma_i = \alpha_i),\\
    \text{find a relational expression } re \text{ such that } 
    freeVars(re) ⊆ S \text{, and } \\
    (\bigwedge [re/\alpha_i] cs) \vdash (\sigma_i = re) \\
    \text{ is valid in the axiomatic system defined by set theoretic axioms}
$$

We now claim that second version of our algorithm (call it $$A2$$) is sound: 

$$
    \text{Theorem 1 (Algorithm A2 is sound): every } re \text{
    returned by } \\ {\sf solve(S,cs,\sigma_i)} \text{ is a solution of }
    (S,\; cs \vdash \sigma_i = \alpha_i).
$$
